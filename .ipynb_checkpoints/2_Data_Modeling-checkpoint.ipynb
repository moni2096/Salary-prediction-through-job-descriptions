{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the preprocessing step we will be eastablishing the baseline for our model. Also, we know that our problem can be best solved by Regression methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#__author__ = Monish Khambhati\n",
    "#__email__ = monish.khambhati@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the train data\n",
    "train_df = pd.read_csv('data/train_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the target features data\n",
    "target_df = pd.read_csv('data/train_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the test features data\n",
    "test_df = pd.read_csv('data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the train and target dataframe\n",
    "train_df = pd.merge(left = train_df,right = target_df,how='inner', on='jobId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the EDA conclusion we know that **jobId** is not related to the target variables. So, I will start by dropping those fetaures from train and test data. And also choosing the salaries which are greater than 0 in **train_df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the dataframe\n",
    "def clean_data(raw_df):\n",
    "    '''remove rows that contain salary <= 0 or duplicate job IDs'''\n",
    "    clean_df = raw_df.drop_duplicates(subset='jobId')\n",
    "    clean_df = clean_df[clean_df.salary>0]\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = clean_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop('jobId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding data to our model we will be writing a function to perform **One Hot Encoding**.\n",
    " - One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_df(df, cat_vars=None, num_vars=None):\n",
    "    '''performs one-hot encoding on all categorical variables and combines result with continous variables'''\n",
    "    cat_df = pd.get_dummies(df[cat_vars])\n",
    "    num_df = df[num_vars].apply(pd.to_numeric)\n",
    "    return pd.concat([cat_df, num_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining categorical variable and numerical variables\n",
    "categorical_vars = ['companyId','jobType', 'degree', 'major', 'industry']\n",
    "numerical_vars = ['yearsExperience', 'milesFromMetropolis']\n",
    "target_var = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = one_hot_encode_df(train_df,cat_vars=categorical_vars, num_vars=numerical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyId_COMP0</th>\n",
       "      <th>companyId_COMP1</th>\n",
       "      <th>companyId_COMP10</th>\n",
       "      <th>companyId_COMP11</th>\n",
       "      <th>companyId_COMP12</th>\n",
       "      <th>companyId_COMP13</th>\n",
       "      <th>companyId_COMP14</th>\n",
       "      <th>companyId_COMP15</th>\n",
       "      <th>companyId_COMP16</th>\n",
       "      <th>companyId_COMP17</th>\n",
       "      <th>...</th>\n",
       "      <th>major_PHYSICS</th>\n",
       "      <th>industry_AUTO</th>\n",
       "      <th>industry_EDUCATION</th>\n",
       "      <th>industry_FINANCE</th>\n",
       "      <th>industry_HEALTH</th>\n",
       "      <th>industry_OIL</th>\n",
       "      <th>industry_SERVICE</th>\n",
       "      <th>industry_WEB</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   companyId_COMP0  companyId_COMP1  companyId_COMP10  companyId_COMP11  \\\n",
       "0                0                0                 0                 0   \n",
       "1                0                0                 0                 0   \n",
       "2                0                0                 0                 0   \n",
       "3                0                0                 0                 0   \n",
       "4                0                0                 0                 0   \n",
       "\n",
       "   companyId_COMP12  companyId_COMP13  companyId_COMP14  companyId_COMP15  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   companyId_COMP16  companyId_COMP17  ...  major_PHYSICS  industry_AUTO  \\\n",
       "0                 0                 0  ...              0              0   \n",
       "1                 0                 0  ...              0              0   \n",
       "2                 0                 0  ...              1              0   \n",
       "3                 0                 0  ...              0              1   \n",
       "4                 0                 0  ...              1              0   \n",
       "\n",
       "   industry_EDUCATION  industry_FINANCE  industry_HEALTH  industry_OIL  \\\n",
       "0                   0                 0                1             0   \n",
       "1                   0                 0                0             0   \n",
       "2                   0                 0                1             0   \n",
       "3                   0                 0                0             0   \n",
       "4                   0                 1                0             0   \n",
       "\n",
       "   industry_SERVICE  industry_WEB  yearsExperience  milesFromMetropolis  \n",
       "0                 0             0               10                   83  \n",
       "1                 0             1                3                   73  \n",
       "2                 0             0               10                   38  \n",
       "3                 0             0                8                   17  \n",
       "4                 0             0                8                   16  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and validation set and establishing the baseline\n",
    " - I will be using sklearn to split the data into training and validation set into 80:20 feataure\n",
    " - Also, the metric that we will choose in this case is Mean Squared Error(MSE). Mean squared error measures the average of the squares of errors, i.e, the difference between actual value (y) and the estimated value (ŷ).\n",
    " - Baseline model would be a simple linear regession model and we will be using it to hypothesize solutions based on the results of the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting target variable from train_salaries which are greater than 0\n",
    "target_df = clean_data(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = target_df.drop('jobId',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and validation set\n",
    "X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(train_df, target_df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = one_hot_encode_df(test_df,cat_vars=categorical_vars, num_vars=numerical_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 predictied salaries:  [[157.66113281]\n",
      " [ 62.4675293 ]\n",
      " [108.64038086]\n",
      " [112.38195801]\n",
      " [ 92.36999512]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a linear regression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fitting the model with the train data\n",
    "lr.fit(X_train_data, y_train_data)\n",
    "\n",
    "# Predicting the model on the validation data\n",
    "y_predict = lr.predict(X_test_data)\n",
    "print(\"The first 5 predictied salaries: \", y_predict[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating our model using validation set by calculating mean squared error\n",
    "mse = mean_squared_error(y_test_data, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384.87103685501\n"
     ]
    }
   ],
   "source": [
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesize a solution\n",
    "#### On the baseline simple regression model the MSE is 384.87. We would try other techniques and also do feature engineering and hyperparameter tuning to imrove model on test set. \n",
    " - The models we will be using to achieve better accuracy are:\n",
    "     - Random Forest Regressor\n",
    "     - Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 60, max_depth = 25, \n",
    "                           min_samples_split = 20, n_jobs = 2, \n",
    "                           max_features = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=25, max_features=30, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=60, n_jobs=2, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the object to training data\n",
    "rf.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753628750770697"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the model accuracy on test set\n",
    "rf.score(X_test_data, y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Predictions on test set:  [156.22881855  61.49589036  96.20134462  99.18286317  95.57143932]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on test data\n",
    "y_predict_rf = rf.predict(X_test_data)\n",
    "print(\"First 5 Predictions on test set: \", y_predict_rf[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371.04312162425936"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean squared error on test set\n",
    "mean_squared_error(y_test_data, y_predict_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Gradient Boosting Regressor object\n",
    "gd = GradientBoostingRegressor(n_estimators = 60, max_depth = 5,loss = 'ls', verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1349.8934           11.56m\n",
      "         2        1228.8101           11.11m\n",
      "         3        1128.7405           10.80m\n",
      "         4        1044.5412           10.77m\n",
      "         5         973.8131           10.66m\n",
      "         6         912.9784           10.45m\n",
      "         7         860.9562           10.32m\n",
      "         8         813.5527           10.11m\n",
      "         9         771.8185           10.01m\n",
      "        10         735.6256            9.83m\n",
      "        11         702.8820            9.66m\n",
      "        12         675.2100            9.50m\n",
      "        13         647.1429            9.35m\n",
      "        14         622.9292            9.15m\n",
      "        15         602.7250            8.96m\n",
      "        16         582.9249            8.76m\n",
      "        17         564.0264            8.49m\n",
      "        18         547.9513            8.21m\n",
      "        19         533.2990            7.95m\n",
      "        20         520.3717            7.63m\n",
      "        21         509.0961            7.34m\n",
      "        22         497.0678            7.04m\n",
      "        23         486.3063            6.78m\n",
      "        24         477.7897            6.51m\n",
      "        25         467.8144            6.24m\n",
      "        26         460.7847            5.99m\n",
      "        27         453.6967            5.74m\n",
      "        28         447.8704            5.51m\n",
      "        29         440.7992            5.28m\n",
      "        30         435.6470            5.06m\n",
      "        31         430.0027            4.84m\n",
      "        32         425.5297            4.63m\n",
      "        33         420.3855            4.43m\n",
      "        34         416.0204            4.23m\n",
      "        35         412.2877            4.04m\n",
      "        36         409.2387            3.85m\n",
      "        37         406.3499            3.67m\n",
      "        38         403.0149            3.49m\n",
      "        39         399.9628            3.31m\n",
      "        40         396.8970            3.15m\n",
      "        41         394.6281            2.97m\n",
      "        42         392.2688            2.80m\n",
      "        43         390.4437            2.64m\n",
      "        44         388.5167            2.48m\n",
      "        45         385.9674            2.32m\n",
      "        46         384.5229            2.16m\n",
      "        47         383.0007            2.04m\n",
      "        48         380.9945            1.95m\n",
      "        49         379.6684            1.80m\n",
      "        50         378.4609            1.66m\n",
      "        51         377.4510            1.51m\n",
      "        52         376.4239            1.37m\n",
      "        53         375.2437            1.21m\n",
      "        54         374.3777            1.05m\n",
      "        55         373.1621           53.16s\n",
      "        56         372.3821           42.97s\n",
      "        57         371.6315           32.50s\n",
      "        58         370.7802           21.89s\n",
      "        59         370.0914           11.04s\n",
      "        60         369.4651            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=5,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=60,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=5, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting object to data\n",
    "gd.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_gd = gd.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371.70423609623873"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test_data, y_predict_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After hypothesizing solutions and testing them using 20% of test data we will develop a solution using object oriented approach and also predicting the salaries on test data. \n",
    " - We would be following object oriented approach to automate the process.\n",
    " - We would be performing cross validation using k-fold cross validation with 5 folds.\n",
    " - We would try to automate the pipeline using the best model and deploy it.\n",
    " - We would also be able to distinguish the power of perfoming k-fold cross validation and pipeline which will improve our mse significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
